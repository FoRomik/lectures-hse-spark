{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ALS').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,31,2.5,1260759144\r",
      "\r\n",
      "1,1029,3.0,1260759179\r",
      "\r\n",
      "1,1061,3.0,1260759182\r",
      "\r\n",
      "1,1129,2.0,1260759185\r",
      "\r\n",
      "1,1172,4.0,1260759205\r",
      "\r\n",
      "1,1263,2.0,1260759151\r",
      "\r\n",
      "1,1287,2.0,1260759187\r",
      "\r\n",
      "1,1293,2.0,1260759148\r",
      "\r\n",
      "1,1339,3.5,1260759125\r",
      "\r\n",
      "1,1343,2.0,1260759131\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head ../data/ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+\n",
      "|movie_id|rating|user_id|\n",
      "+--------+------+-------+\n",
      "|      31|   2.5|      1|\n",
      "|    1029|   3.0|      1|\n",
      "|    1061|   3.0|      1|\n",
      "|    1129|   2.0|      1|\n",
      "|    1172|   4.0|      1|\n",
      "+--------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "ratings_rdd = spark.sparkContext \\\n",
    "                   .textFile('../data/ratings.csv') \\\n",
    "                   .map(lambda line: line.split(',')) \\\n",
    "                   .map(lambda values: Row(user_id=int(values[0]), \n",
    "                                           movie_id=int(values[1]), \n",
    "                                           rating=float(values[2])))\n",
    "\n",
    "ratings_df = spark.createDataFrame(ratings_rdd)\n",
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "(training, test) = ratings_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# TODO: train ALS model with rank=8, maxIter=10 \n",
    "# and nonnegative=True\n",
    "\n",
    "als = ALS(rank=8, \n",
    "          maxIter=10, \n",
    "          userCol='user_id',\n",
    "          itemCol='movie_id')\n",
    "\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------------------------------+\n",
      "|id |features                                                                                          |\n",
      "+---+--------------------------------------------------------------------------------------------------+\n",
      "|10 |[0.29715133, -0.67561156, 1.4933176, 0.09223974, 0.30582935, 0.53732026, 0.64945066, 0.50541675]  |\n",
      "|20 |[0.01752448, -1.1346962, 0.5675352, -0.6137143, 0.044949386, 1.3254719, 0.85583174, -0.5330784]   |\n",
      "|30 |[-0.18940143, -1.3753406, 0.7915036, -0.36732832, -0.30896997, 0.66650254, 0.16912146, 1.0029738] |\n",
      "|40 |[0.51354086, -0.62774503, 1.2171535, -0.5378062, -0.50973356, 0.917853, -0.027028423, 0.7851973]  |\n",
      "|50 |[-0.23169115, -0.88650054, 1.1549692, -0.45893127, 0.064756595, 0.62241155, 0.2911138, 0.38844243]|\n",
      "+---+--------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.userFactors.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import isnan\n",
    "\n",
    "# TODO: make predictions for test data\n",
    "\n",
    "pred = model.transform(test)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='rmse',\n",
    "                                labelCol='rating',\n",
    "                                predictionCol='prediction')\n",
    "\n",
    "# TODO: evaluate predictions with RegressionEvaluator\n",
    "# NOTE: remove records with isnan('prediction') == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9121674395309523"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(pred.filter(~isnan('prediction')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
